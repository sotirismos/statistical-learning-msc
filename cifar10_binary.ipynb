{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image classification (CIFAR-10 dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
    "\n",
    "The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class.\n",
    "\n",
    "The archive contains the files data_batch_1, data_batch_2, ..., data_batch_5, as well as test_batch. Each of these files is a Python \"pickled\" object produced with cPickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preprocessing_utils import unpickle_file\n",
    "\n",
    "# specify the file path of a specific batch\n",
    "file = \"cifar-10-python/data_batch_1\"\n",
    "\n",
    "batch_data = unpickle_file(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The keys in the dictionary are byte strings (bytes) rather than standard strings. In Python, a byte string is prefixed with b, like b'batch_label'\n",
    "print(list(batch_data.keys()))\n",
    "\n",
    "# Convert the byte strings to standard strings\n",
    "keys = [key.decode(\"utf-8\") for key in batch_data.keys()]\n",
    "print(keys)\n",
    "\n",
    "# Update the keys in the dictionary with the standard strings\n",
    "batch_data = {key.decode(\"utf-8\"): value for key, value in batch_data.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is a 10000x3072 numpy array of uint8s. \n",
    "Each row of the array stores a 32x32 colour image. \n",
    "The first 1024 entries contain the red channel values, the next 1024 the green, and the final 1024 the blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(batch_data[\"data\"].shape)\n",
    "print(type(batch_data[\"data\"]))\n",
    "\n",
    "print(batch_data[\"data\"][0].shape)\n",
    "print(type(batch_data[\"data\"][0][0]))\n",
    "\n",
    "print(batch_data[\"labels\"][0:10])\n",
    "print(batch_data[\"filenames\"][0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [img_path.decode(\"utf-8\") for img_path in batch_data[\"filenames\"]]\n",
    "print(images[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we can preview 5 random images from our batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preprocessing_utils import display_images\n",
    "from data_preprocessing_utils import preprocess_images\n",
    "\n",
    "# Extract data and labels\n",
    "images = batch_data[\"data\"]\n",
    "labels = batch_data[\"labels\"]\n",
    "\n",
    "# TODO: Analyze this function\n",
    "images_normalized = preprocess_images(images)\n",
    "\n",
    "# CIFAR-10 class names\n",
    "class_names = [\n",
    "    \"airplane\",\n",
    "    \"automobile\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    "]\n",
    "\n",
    "# Display images\n",
    "display_images(images_normalized, labels, class_names, num_images=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preprocessing_utils import load_cifar10_data\n",
    "\n",
    "data_dir = \"./cifar-10-python\"\n",
    "\n",
    "x_train, y_train, x_test, y_test = load_cifar10_data(data_dir)\n",
    "\n",
    "print(\"x_train.shape =\", x_train.shape)\n",
    "print(type(x_train[0]))\n",
    "print(type(x_train[0][0]))\n",
    "\n",
    "print(\"y_train.shape =\", y_train.shape)\n",
    "print(type(y_train[0]))\n",
    "\n",
    "print(\"x_test.shape =\", x_test.shape)\n",
    "print(type(x_test[0]))\n",
    "print(type(x_test[0][0]))\n",
    "\n",
    "\n",
    "print(\"y_test.shape =\", y_test.shape)\n",
    "print(type(y_test[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess the training & testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preprocessing_utils import normalize_data\n",
    "\n",
    "# Normalize the data without reshaping\n",
    "x_train_normalized = normalize_data(x_train)\n",
    "x_test_normalized = normalize_data(x_test)\n",
    "\n",
    "print(\"Normalized data shape:\", x_train_normalized.shape)\n",
    "print(\"First pixel value before normalization:\", x_train[0, 0])\n",
    "print(\"First pixel value after normalization:\", x_train_normalized[0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preprocessing_utils import display_training_class_distribution\n",
    "\n",
    "display_training_class_distribution(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: In order to do a 10-class classification problem, i need to create 10 one-vs-all SVMs (for my custom implementation). Sklearn does it automatically. So, for my implementation I'm going to create a binary classification ONLY for a specific class and I'm goind to compare the results with sklearn's SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: So, in essense these are 2 different problems, so i need to create 2 different datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Analyze why you took a smaller sample of the original dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook analyzes the binary classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 22 Samples from Each Class\n",
    "import numpy as np\n",
    "\n",
    "train_selected_indices = []\n",
    "test_selected_indices = []\n",
    "\n",
    "train_target_class_indices = np.where(y_train == 0)[0][0:1000]\n",
    "test_target_class_indices = np.where(y_test == 0)[0][0:1000]\n",
    "\n",
    "\n",
    "# Loop over each class label (1 to 9)\n",
    "for label in range(1, 10):\n",
    "    # Find the indices of all samples with this label\n",
    "    train_label_indices = np.where(y_train == label)[0]\n",
    "    test_label_indices = np.where(y_test == label)[0]\n",
    "\n",
    "    # Randomly select 22 samples from these indices\n",
    "    train_selected_label_indices = np.random.choice(\n",
    "        train_label_indices, size=100, replace=False\n",
    "    )\n",
    "    test_selected_label_indices = np.random.choice(\n",
    "        test_label_indices, size=100, replace=False\n",
    "    )\n",
    "\n",
    "    # Add these indices to the list\n",
    "    train_selected_indices.extend(train_selected_label_indices)\n",
    "    test_selected_indices.extend(test_selected_label_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Selected Indices to a Numpy Array and Shuffle\n",
    "\n",
    "# Convert the list to a numpy array\n",
    "train_selected_indices = np.array(train_selected_indices)\n",
    "test_selected_indices = np.array(test_selected_indices)\n",
    "\n",
    "# Shuffle the indices to mix samples from different classes\n",
    "np.random.shuffle(train_selected_indices)\n",
    "np.random.shuffle(test_selected_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset the data\n",
    "\n",
    "x_train_subset_1 = x_train_normalized[train_target_class_indices]\n",
    "x_train_subset_2 = x_train_normalized[train_selected_indices]\n",
    "x_test_subset_1 = x_train_normalized[test_target_class_indices]\n",
    "x_test_subset_2 = x_train_normalized[test_selected_indices]\n",
    "\n",
    "y_train_subset_1 = y_train[train_target_class_indices]\n",
    "y_train_subset_2 = y_train[train_selected_indices]\n",
    "y_test_subset_1 = y_train[test_target_class_indices]\n",
    "y_test_subset_2 = y_train[test_selected_indices]\n",
    "\n",
    "print(\"x_train_subset_1.shape:\", x_train_subset_1.shape)\n",
    "print(\"x_train_subset_2.shape:\", x_train_subset_2.shape)\n",
    "print(\"x_test_subset_1.shape:\", x_test_subset_1.shape)\n",
    "print(\"x_test_subset_2.shape:\", x_test_subset_2.shape)\n",
    "\n",
    "print(\"y_train_subset_1.shape:\", y_train_subset_1.shape)\n",
    "print(\"y_train_subset_2.shape:\", y_train_subset_2.shape)\n",
    "print(\"y_test_subset_1.shape:\", y_test_subset_1.shape)\n",
    "print(\"y_test_subset_2.shape:\", y_test_subset_2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_final = np.concatenate((x_train_subset_1, x_train_subset_2))\n",
    "y_train_final = np.concatenate((y_train_subset_1, y_train_subset_2))\n",
    "\n",
    "x_test_final = np.concatenate((x_test_subset_1, x_test_subset_2))\n",
    "y_test_final = np.concatenate((y_test_subset_1, y_test_subset_2))\n",
    "\n",
    "\n",
    "print(\"x_train_final.shape:\", x_train_final.shape)\n",
    "print(\"y_train_final.shape:\", y_train_final.shape)\n",
    "print(\"x_test_final.shape:\", x_test_final.shape)\n",
    "print(\"y_test_final.shape:\", y_test_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_final = np.where(y_train_final == 1, 1, -1)\n",
    "y_test_final = np.where(y_test_final == 1, 1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: (Analyze this): There is a reduction of dimensions with the PCA technique while maintaining 90% of the distribution. The dimension of the data is reduced from 3072 to x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "import numpy as np\n",
    "\n",
    "# TODO: Analyze how PCA works with sklearn (the arguments and the return values)\n",
    "pca = decomposition.PCA(n_components=0.9, svd_solver=\"full\", random_state=0)\n",
    "x_train_final = pca.fit_transform(x_train_final)\n",
    "x_test_final = pca.transform(x_test_final)\n",
    "\n",
    "print(\"x_train_final.shape =\", x_train_final.shape)\n",
    "print(\"x_test.shape =\", x_test_final.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Maybe visualize some stuff on the dimensions of the first and second eigenvector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Analyze MoschosSVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`grid_search` performs K-fold cross validation & evaluates for various parameter values. \n",
    "\n",
    "Accuracy is chosen as the evaluation metric, because the classes are weighted.\n",
    "\n",
    "`plot_grid_search` generates plots for accuracy and training time. \n",
    "\n",
    "`evaluate_model` retrains the best model on the entire training set and evaluates it on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MoschosSVM (Linear Kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ Loss = \\mathbf{w}^T\\mathbf{w} + C\\sum_{k=1}^R\\varepsilon_{k}\\ $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kernel: $ K(\\mathbf{x}, \\mathbf{x}') = \\langle\\mathbf{x},\\mathbf{x}'\\rangle $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from svm import MoschosSVM\n",
    "from model_training_utils import grid_search\n",
    "\n",
    "param_dict = {\"C\": (0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0)}\n",
    "\n",
    "model = MoschosSVM(kernel=\"linear\")\n",
    "\n",
    "results = grid_search(model, param_dict, x_train_final, y_train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from model_training_utils import plot_grid_search\n",
    "\n",
    "plot_grid_search(results, \"C\", None, \"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from model_training_utils import evaluate_model\n",
    "\n",
    "\n",
    "res = evaluate_model(\n",
    "    \"My Linear SVM\",\n",
    "    model,\n",
    "    results[\"best_params\"],\n",
    "    x_train_final,\n",
    "    y_train_final,\n",
    "    x_test_final,\n",
    "    y_test_final,\n",
    ")\n",
    "\n",
    "final_results.append(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sklearn (Linear Kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "param_dict = {\"C\": (0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0)}\n",
    "\n",
    "model = svm.SVC(kernel=\"linear\")\n",
    "results = grid_search(model, param_dict, x_train_final, y_train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_grid_search(results, \"C\", None, \"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "res = evaluate_model(\n",
    "    \"Linear SVM\",\n",
    "    model,\n",
    "    results[\"best_params\"],\n",
    "    x_train_final,\n",
    "    y_train_final,\n",
    "    x_test_final,\n",
    "    y_test_final,\n",
    ")\n",
    "final_results.append(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MoschosSVM (Polynomial Kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kernel: $ K(\\mathbf{x}, \\mathbf{x}') = (\\gamma\\langle\\mathbf{x},\\mathbf{x}'\\rangle+r)^d $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from model_training_utils import grid_search\n",
    "from svm import MoschosSVM\n",
    "\n",
    "param_dict = {\"C\": (0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0), \"degree\": (2, 3, 4, 5)}\n",
    "\n",
    "model = MoschosSVM(kernel=\"poly\")\n",
    "results = grid_search(model, param_dict, x_train_final, y_train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_grid_search(results, \"C\", \"degree\", \"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = evaluate_model(\n",
    "    \"My Polynomial SVM\",\n",
    "    model,\n",
    "    results[\"best_params\"],\n",
    "    x_train_final,\n",
    "    y_train_final,\n",
    "    x_test_final,\n",
    "    y_test_final,\n",
    ")\n",
    "final_results.append(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sklearn (Polynomial Kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Βελτιστοποίηση του sklearn.svm.SVC με polynomial kernel στο μικρο training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "param_dict = {\"C\": (0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0), \"degree\": (2, 3, 4, 5)}\n",
    "\n",
    "model = svm.SVC(kernel=\"poly\")\n",
    "results = grid_search(model, param_dict, x_train_final, y_train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_grid_search(results, \"C\", \"degree\", \"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = evaluate_model(\n",
    "    \"Polynomial SVM\",\n",
    "    model,\n",
    "    results[\"best_params\"],\n",
    "    x_train_final,\n",
    "    y_train_final,\n",
    "    x_test_final,\n",
    "    y_test_final,\n",
    ")\n",
    "final_results.append(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MoschosSVM (RBF Kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Η βελτιστοποίηση του MySVM με rbf kernel πραγματοποιείται ως προς τις παραμέτρους C και gamma. Το gamma δείχνει πόσο μακριά φτάνει η επιρροή ενός παραδείγματος."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kernel: $ K(\\mathbf{x}, \\mathbf{x}') = e^{-\\gamma||\\mathbf{x}-\\mathbf{x}'||^2} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "param_dict = {\"C\": (0.001, 0.01, 0.1, 1.0, 10.0, 100.0), \"gamma\": (0.01, 0.1, 1.0)}\n",
    "\n",
    "model = MoschosSVM(kernel=\"rbf\")\n",
    "results = grid_search(model, param_dict, x_train_final, y_train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_grid_search(results, \"C\", \"gamma\", \"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "res = evaluate_model(\n",
    "    \"My RBF SVM\",\n",
    "    model,\n",
    "    results[\"best_params\"],\n",
    "    x_train_final,\n",
    "    y_train_final,\n",
    "    x_test_final,\n",
    "    y_test_final,\n",
    ")\n",
    "final_results.append(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sklearn (RBF Kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "param_dict = {\"C\": (0.001, 0.01, 0.1, 1.0, 10.0, 100.0), \"gamma\": (0.01, 0.1, 1.0)}\n",
    "\n",
    "model = svm.SVC(kernel=\"rbf\")\n",
    "results = grid_search(model, param_dict, x_train_final, y_train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_grid_search(results, \"C\", \"gamma\", \"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res = evaluate_model(\n",
    "    \"RBF SVM\",\n",
    "    model,\n",
    "    results[\"best_params\"],\n",
    "    x_train_final,\n",
    "    y_train_final,\n",
    "    x_test_final,\n",
    "    y_test_final,\n",
    ")\n",
    "final_results.append(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MoschosSVM (MLP Kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict = {\"C\": (0.001, 0.01, 0.1, 1.0, 10.0, 100.0), \"gamma\": (0.001, 0.01, 0.1)}\n",
    "\n",
    "model = MoschosSVM(kernel=\"sigmoid\")\n",
    "results = grid_search(model, param_dict, x_train_final, y_train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_grid_search(results, \"C\", \"gamma\", \"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = evaluate_model(\n",
    "    \"My MLP SVM\",\n",
    "    model,\n",
    "    results[\"best_params\"],\n",
    "    x_train_final,\n",
    "    y_train_final,\n",
    "    x_test_final,\n",
    "    y_test_final,\n",
    ")\n",
    "final_results.append(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sklearn (MLP Kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kernel: $ K(\\mathbf{x}, \\mathbf{x}') = tanh(\\gamma\\langle\\mathbf{x},\\mathbf{x}'\\rangle+r) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict = {\"C\": (0.001, 0.01, 0.1, 1.0, 10.0, 100.0), \"gamma\": (0.001, 0.01, 0.1)}\n",
    "\n",
    "model = svm.SVC(kernel=\"sigmoid\")\n",
    "results = grid_search(model, param_dict, x_train_final, y_train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_grid_search(results, \"C\", \"gamma\", \"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = evaluate_model(\n",
    "    \"MLP SVM\",\n",
    "    model,\n",
    "    results[\"best_params\"],\n",
    "    x_train_final,\n",
    "    y_train_final,\n",
    "    x_test_final,\n",
    "    y_test_final,\n",
    ")\n",
    "final_results.append(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$d_p(\\mathbf{x}, \\mathbf{y}) = \\sqrt[p]{\\sum_{i}|x_i-y_i|^p}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "param_dict = {\"n_neighbors\": (1, 2, 5, 10), \"p\": (1, 2, 3)}\n",
    "\n",
    "model = neighbors.KNeighborsClassifier()\n",
    "results = grid_search(model, param_dict, x_train_final, y_train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_grid_search(results, \"n_neighbors\", \"p\", \"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = evaluate_model(\n",
    "    \"Nearest Neighbors\",\n",
    "    model,\n",
    "    results[\"best_params\"],\n",
    "    x_train_final,\n",
    "    y_train_final,\n",
    "    x_test_final,\n",
    "    y_test_final,\n",
    ")\n",
    "final_results.append(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Nearest Class Centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict = {\"shrink_threshold\": np.arange(0, 1.1, 0.1)}\n",
    "\n",
    "model = neighbors.NearestCentroid()\n",
    "results = grid_search(model, param_dict, x_train_final, y_train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_grid_search(results, \"shrink_threshold\", None, \"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = evaluate_model(\n",
    "    \"Nearest Class Centroid\",\n",
    "    model,\n",
    "    results[\"best_params\"],\n",
    "    x_train_final,\n",
    "    y_train_final,\n",
    "    x_test_final,\n",
    "    y_test_final,\n",
    ")\n",
    "final_results.append(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "final_results_df = pd.DataFrame(final_results)\n",
    "final_results_df = final_results_df.style.set_table_styles(\n",
    "    [{\"selector\": \"th\", \"props\": [(\"text-align\", \"left\")]}]\n",
    ")\n",
    "final_results_df = final_results_df.set_properties(\n",
    "    subset=[\"text-align\"], **{\"text-align\": \"left\"}\n",
    ").hide(axis=\"index\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
